{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed22f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycona in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: cpmpy>=0.9 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from pycona) (0.9.22)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from pycona) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.5 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from cpmpy>=0.9->pycona) (1.21.5)\n",
      "Requirement already satisfied: ortools>=5.0 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from cpmpy>=0.9->pycona) (9.5.2237)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn->pycona) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn->pycona) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from scikit-learn->pycona) (1.1.1)\n",
      "Requirement already satisfied: absl-py>=0.13 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from ortools>=5.0->cpmpy>=0.9->pycona) (1.3.0)\n",
      "Requirement already satisfied: protobuf>=4.21.5 in c:\\users\\gertj\\anaconda3\\envs\\cv\\lib\\site-packages (from ortools>=5.0->cpmpy>=0.9->pycona) (4.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycona\n",
    "import pandas as pd\n",
    "from pycona import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165f47f",
   "metadata": {},
   "source": [
    "### Comparing interactive CA systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc632561",
   "metadata": {},
   "source": [
    "For the introductory example, we only used GrowAcq algorithm, with its default settings. In this notebook, we will first run and compare different interactive CA algorithms, and then we will see how we can customize their configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01f0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProblemInstance: \n",
      "\n",
      "Name nurse_rostering_nurses8_shifts3_days2_nurses_per_shift2.\n",
      "\n",
      "Parameters {'shifts_per_day': 3, 'num_days': 2, 'num_nurses': 8, 'nurses_per_shift': 2}.\n",
      "\n",
      "Variables: [[[shifts[0,0,0] shifts[0,0,1]]\n",
      "  [shifts[0,1,0] shifts[0,1,1]]\n",
      "  [shifts[0,2,0] shifts[0,2,1]]]\n",
      "\n",
      " [[shifts[1,0,0] shifts[1,0,1]]\n",
      "  [shifts[1,1,0] shifts[1,1,1]]\n",
      "  [shifts[1,2,0] shifts[1,2,1]]]].\n",
      "\n",
      "Language: [(AV4) == (AV5), (AV4) != (AV5), (AV4) < (AV5), (AV4) > (AV5), (AV4) >= (AV5), (AV4) <= (AV5)].\n"
     ]
    }
   ],
   "source": [
    "from pycona.benchmarks import construct_nurse_rostering\n",
    "\n",
    "# we use the running example on nurse rostering from the introductory tutorial\n",
    "instance, oracle = construct_nurse_rostering(3, 2, 8, 2)\n",
    "print(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d089bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Customizing Interactive CA systems "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266e662",
   "metadata": {},
   "source": [
    "Each interactive CA algorithm can be configured in different ways for each of the 3 main subcomponents of interactive CA systems:\n",
    "\n",
    "- qgen: An instance of QGenBase, default is None. The query generation system to be used to generate top-level queries.\n",
    "- find_scope: An instance of FindScopeBase, default is None. The FindScope system to be used for finding the scope of violated constraints.\n",
    "- findc: An instance of FindCBase, default is None. The FindConstraint system to be used for finding the exact violated constraints in the given scopes.\n",
    "\n",
    "For each of the subcomponents several choices are implemented, based on the literature. Each subcomponent of CA is implemented in a class, with different implementations of that subcomponent subclassing it.\n",
    "\n",
    "Until now, we used the default settings in **PyConA** for interactive CA systems. We will now focus on how to customize the behaviour of a given Interactive CA system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c96d8",
   "metadata": {},
   "source": [
    "#### Using a custom CA Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7743fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running growacq with <pycona.active_algorithms.mquacq2.MQuAcq2 object at 0x000001F8E240B308> as inner algorithm\n",
      "\n",
      "Learned 0 constraints in 0 queries.\n",
      "...L..\n",
      "Learned 1 constraints in 5 queries.\n",
      "....L....L..\n",
      "Learned 3 constraints in 15 queries.\n",
      ".....L.....L...L.\n",
      "Learned 6 constraints in 29 queries.\n",
      ".....L...L.....L...L.\n",
      "Learned 10 constraints in 46 queries.\n",
      ".....L......L....L..L....L..\n",
      "Learned 15 constraints in 69 queries.\n",
      ".....L.....L....\n",
      "Learned 17 constraints in 83 queries.\n",
      ".....L......L...L.\n",
      "Learned 20 constraints in 98 queries.\n",
      "........L........L......\n",
      "Learned 22 constraints in 120 queries.\n",
      ".......L.....L.....L....\n",
      "Learned 25 constraints in 141 queries.\n",
      "......L.......L...L......L...\n",
      "Learned 29 constraints in 166 queries.\n",
      "......L......L....L......L...L..\n",
      "Learned 34 constraints in 193 queries.\n"
     ]
    }
   ],
   "source": [
    "# Creating probabilistic environment, using the default settings for all subcomponents\n",
    "env = ProbaActiveCAEnv(qgen=PQGen(), find_scope=FindScope2(), findc=FindC())\n",
    "\n",
    "ga2 = GrowAcq(env)\n",
    "learned_instance = ga2.learn(instance, oracle=oracle, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e49b6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running growacq with <pycona.active_algorithms.mquacq2.MQuAcq2 object at 0x000001F8E25B29C8> as inner algorithm\n",
      "\n",
      "Learned 0 constraints in 0 queries.\n",
      ".....L..\n",
      "Learned 1 constraints in 7 queries.\n",
      ".......L.......L..\n",
      "Learned 3 constraints in 23 queries.\n",
      "........L.........L......L.\n",
      "Learned 6 constraints in 47 queries.\n",
      ".......L.....L........L......L.\n",
      "Learned 10 constraints in 74 queries.\n",
      ".......L..........L......L....L.......L..\n",
      "Learned 15 constraints in 110 queries.\n",
      ".......L........L....\n",
      "Learned 17 constraints in 129 queries.\n",
      ".......L........L......L.\n",
      "Learned 20 constraints in 151 queries.\n",
      ".............L..............L......\n",
      "Learned 22 constraints in 184 queries.\n",
      "..........L..........L.........L....\n",
      "Learned 25 constraints in 217 queries.\n",
      "........L...........L........L.............L...\n",
      "Learned 29 constraints in 260 queries.\n",
      "........L........L.............L.....L.........L......\n",
      "Learned 34 constraints in 309 queries.\n"
     ]
    }
   ],
   "source": [
    "# Lets use the older 'FindScope' instead of FindScope2, and see what the effect is\n",
    "env = ProbaActiveCAEnv(qgen=PQGen(), find_scope=FindScope(), findc=FindC())\n",
    "\n",
    "ga1 = GrowAcq(env)\n",
    "learned_instance = ga1.learn(instance, oracle=oracle, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10f06cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>tot_q</th>\n",
       "      <th>top_lvl_q</th>\n",
       "      <th>tfs_q</th>\n",
       "      <th>tfc_q</th>\n",
       "      <th>avg_q_size</th>\n",
       "      <th>avg_gen_time</th>\n",
       "      <th>avg_t</th>\n",
       "      <th>max_t</th>\n",
       "      <th>tot_t</th>\n",
       "      <th>conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>growacq findscope2</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>193</td>\n",
       "      <td>71</td>\n",
       "      <td>77</td>\n",
       "      <td>45</td>\n",
       "      <td>4.2487</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>5.5933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>growacq findscope</th>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>309</td>\n",
       "      <td>75</td>\n",
       "      <td>188</td>\n",
       "      <td>46</td>\n",
       "      <td>3.7443</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>5.8530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      CL  tot_q  top_lvl_q  tfs_q  tfc_q  avg_q_size  \\\n",
       "growacq findscope2 0  34    193         71     77     45      4.2487   \n",
       "growacq findscope  0  34    309         75    188     46      3.7443   \n",
       "\n",
       "                      avg_gen_time   avg_t   max_t   tot_t  conv  \n",
       "growacq findscope2 0        0.0496  0.0290  0.1431  5.5933     1  \n",
       "growacq findscope  0        0.0498  0.0189  0.1426  5.8530     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can compare the detailed statistics:\n",
    "pd.concat([ga2.env.metrics.short_statistics, \n",
    "           ga1.env.metrics.short_statistics], keys=[\"growacq findscope2\", \"growacq findscope\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b7190",
   "metadata": {},
   "source": [
    "#### Comparing different algorithms\n",
    "\n",
    "First the classic QuAcq, MQuAcq and MQuAcq2 algorithms.\n",
    "\n",
    "_(by default they do not use a probabilistic environment, though you can change that)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87bfbeba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some patience needed\n",
    "qa = QuAcq()\n",
    "learned_instance = qa.learn(instance, oracle=oracle)\n",
    "\n",
    "mqa = MQuAcq()\n",
    "learned_instance = mqa.learn(instance, oracle=oracle)\n",
    "\n",
    "mqa2 = MQuAcq2()\n",
    "learned_instance = mqa2.learn(instance, oracle=oracle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bea47c",
   "metadata": {},
   "source": [
    "Then, the more recent 'GrowAcq' meta-algorithm\n",
    "\n",
    "(includes a probabilistic environment that guides query generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574847fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga24 = GrowAcq()  # AAAI24 version, decision tree with features\n",
    "learned_instance = ga24.learn(instance, oracle=oracle)\n",
    "\n",
    "ga23 = GrowAcq(ProbaActiveCAEnv(classifier=CountsPredictor()))  # CP23 version, counting based probabilities\n",
    "learned_instance = ga23.learn(instance, oracle=oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5233f789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CL</th>\n",
       "      <th>tot_q</th>\n",
       "      <th>top_lvl_q</th>\n",
       "      <th>tfs_q</th>\n",
       "      <th>tfc_q</th>\n",
       "      <th>avg_q_size</th>\n",
       "      <th>avg_gen_time</th>\n",
       "      <th>avg_t</th>\n",
       "      <th>max_t</th>\n",
       "      <th>tot_t</th>\n",
       "      <th>conv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>qa</th>\n",
       "      <td>34</td>\n",
       "      <td>226</td>\n",
       "      <td>39</td>\n",
       "      <td>166</td>\n",
       "      <td>21</td>\n",
       "      <td>6.6283</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.1174</td>\n",
       "      <td>1.2398</td>\n",
       "      <td>26.5332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mqa</th>\n",
       "      <td>34</td>\n",
       "      <td>168</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>5.6071</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>1.1710</td>\n",
       "      <td>2.7558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mqa2</th>\n",
       "      <td>34</td>\n",
       "      <td>187</td>\n",
       "      <td>36</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "      <td>4.7968</td>\n",
       "      <td>0.4650</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>1.2333</td>\n",
       "      <td>8.2955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ga23</th>\n",
       "      <td>34</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5.6667</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>4.2206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ga24</th>\n",
       "      <td>34</td>\n",
       "      <td>85</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.2471</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>3.7040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CL  tot_q  top_lvl_q  tfs_q  tfc_q  avg_q_size  avg_gen_time   avg_t  \\\n",
       "qa    34    226         39    166     21      6.6283        0.6521  0.1174   \n",
       "mqa   34    168         61     98      9      5.6071        0.3217  0.0164   \n",
       "mqa2  34    187         36    115     25      4.7968        0.4650  0.0444   \n",
       "ga23  34     90         88      0      2      5.6667        0.0447  0.0469   \n",
       "ga24  34     85         79      2      4      5.2471        0.0414  0.0436   \n",
       "\n",
       "       max_t    tot_t  conv  \n",
       "qa    1.2398  26.5332     1  \n",
       "mqa   1.1710   2.7558     1  \n",
       "mqa2  1.2333   8.2955     1  \n",
       "ga23  0.1430   4.2206     1  \n",
       "ga24  0.1589   3.7040     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can compare the detailed statistics:\n",
    "out = pd.concat([a.env.metrics.short_statistics for a in [qa,mqa,mqa2,ga23,ga24]])\n",
    "out.index = [\"qa\",\"mqa\",\"mqa2\",\"ga23\",\"ga24\"]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce06ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
